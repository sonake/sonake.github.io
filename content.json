[{"title":"数据结构与算法(三)","date":"2021-10-25T21:04:22.000Z","path":"2021/10/25/数据结构与算法-三/","text":"这里主要说一下多项式和简单的循环问题,留言区留下你们的答案 上问题12345678/*** 循环输出范围内的数字，这可能是最容易想到的方式，有没有其他办法呢，大家可以评论留言 */ class Demo&#123; public static void main(String[] args)&#123; for(int i=10;i&lt;10;i++)&#123;&#125; &#125;&#125; 12345678/*** f(x)=an·x^n+an-1·x^(n-1)+…+a2·x^2+a1·x+a0 多项式如何用代码实现呢 */ class Demo&#123; public static double sum(int n, double[] a, double x)&#123; // TODO &#125;&#125;","tags":[{"name":"java","slug":"java","permalink":"sonake.github.io/tags/java/"},{"name":"数据结构","slug":"数据结构","permalink":"sonake.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"rabbitmq简单实践","date":"2019-12-27T14:39:54.000Z","path":"2019/12/27/rabbitmq简单实践/","text":"简介AMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。 消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。RabbitMQ是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 个人想到最常用的高并发场景可能是秒杀，这里自己做了一个简单的demo，进行了实践。 项目地址: rabbitmq秒杀实践第一步: 新建springboot项目，引入依赖,增加库表12345678910111213141516171819202122232425262728&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--redis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--消息队列--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 这里springboot的版本为2.2.0，持久层选择mybatis-plus,消息队列配合redis实现高并发场景下的削峰，主要是redis有优秀的读写速度，可以快速处理请求，将请求结果处理后，返回用户，通过消息队列暂存结果，监听队列，程序持久化结果到数据库。 1234567891011121314151617181920212223242526272829303132333435363738394041424344/*Navicat MariaDB Data TransferSource Server : localhostSource Server Version : 100214Source Host : localhost:3308Source Database : seconds_killTarget Server Type : MariaDBTarget Server Version : 100214File Encoding : 65001Date: 2019-12-26 18:30:26*/SET FOREIGN_KEY_CHECKS=0;-- ------------------------------ Table structure for goods-- ----------------------------DROP TABLE IF EXISTS `goods`;CREATE TABLE `goods` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键', `goods_name` varchar(255) NOT NULL COMMENT '商品名称', `store` int(11) NOT NULL COMMENT '价格', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mb4;-- ------------------------------ Records of goods-- ----------------------------INSERT INTO `goods` VALUES ('1', 'watch', '150');INSERT INTO `goods` VALUES ('2', 'pencil', '150');-- ------------------------------ Table structure for orders-- ----------------------------DROP TABLE IF EXISTS `orders`;CREATE TABLE `orders` ( `id` varchar(255) NOT NULL, `order_name` varchar(255) NOT NULL, `order_user` varchar(255) NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=36956 DEFAULT CHARSET=utf8mb4; orders订单表id，考虑到实际业务，订单id必须唯一，使用mybatis-plus的分布式全局唯一id 123456789101112131415161718192021package com.sonake.seconds.kill.demo.domain;import com.baomidou.mybatisplus.annotation.IdType;import com.baomidou.mybatisplus.annotation.TableId;import com.baomidou.mybatisplus.annotation.TableName;import lombok.Data;/** * @author ：xzyuan * @date ：Created in 2019/12/26 13:42 * @description： * @version: */@TableName(\"orders\")@Datapublic class Orders &#123; @TableId(type = IdType.ID_WORKER_STR) private String id; private String orderName; private String orderUser;&#125; 第二步：添加配置12345678910111213141516171819202122232425262728293031323334353637spring: application: name: seconds_kill datasource: url: jdbc:mysql://127.0.0.1:3308/seconds_kill?rewriteBatchedStatements=true&amp;serverTimezone=GMT%2b8 password: root username: root driver-class-name: com.mysql.cj.jdbc.Driver hikari: connection-timeout: 30000 max-lifetime: 1800000 max-pool-size: 15 min-idle: 200 connection-test-query: select 1 rabbitmq: virtual-host: / host: localhost username: guest password: guest listener: simple: retry: enabled: true max-attempts: 10 #最大重试次数 max-interval: 10000 #重试最大时间间隔(ms) initial-interval: #c重试间隔时间(ms) multiplier: 5 #应用于前一重试间隔的乘法器。 redis: host: localhost port: 6379 jedis: pool: max-active: 1024 max-wait: -1ms max-idle: 200 database: 2 第三步：代码实现这里主要说一下与消息队列主要的代码，数据库常用的crud不做展示，具体可看项目demo rabbitmq的配置,有关rabbitmq的参数可以自行百度，1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package com.sonake.seconds.kill.demo.config;import org.springframework.amqp.core.*;import org.springframework.amqp.support.converter.Jackson2JsonMessageConverter;import org.springframework.amqp.support.converter.MessageConverter;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author ：xzyuan * @date ：Created in 2019/12/26 14:19 * @description： * @version: */@Configurationpublic class RabbitMQConfig &#123; //库存交换机 public static final String STORY_EXCHANGE = \"STORY_EXCHANGE\"; //订单交换机 public static final String ORDER_EXCHANGE = \"ORDER_EXCHANGE\"; //库存队列 public static final String STORY_QUEUE = \"STORY_QUEUE\"; //订单队列 public static final String ORDER_QUEUE = \"ORDER_QUEUE\"; //库存路由键 public static final String STORY_ROUTING_KEY = \"STORY_ROUTING_KEY\"; //订单路由键 public static final String ORDER_ROUTING_KEY = \"ORDER_ROUTING_KEY\"; @Bean public MessageConverter messageConverter() &#123; return new Jackson2JsonMessageConverter(); &#125; //创建库存交换机 @Bean public Exchange getStoryExchange() &#123; return ExchangeBuilder.directExchange(STORY_EXCHANGE).durable(true).build(); &#125; //创建库存队列 @Bean public Queue getStoryQueue() &#123; return new Queue(STORY_QUEUE); &#125; //库存交换机和库存队列绑定 @Bean public Binding bindStory() &#123; return BindingBuilder.bind(getStoryQueue()).to(getStoryExchange()).with(STORY_ROUTING_KEY).noargs(); &#125; //创建订单队列 @Bean public Queue getOrderQueue() &#123; return new Queue(ORDER_QUEUE); &#125; //创建订单交换机 @Bean public Exchange getOrderExchange() &#123; return ExchangeBuilder.directExchange(ORDER_EXCHANGE).durable(true).build(); &#125; //订单队列与订单交换机进行绑定 @Bean public Binding bindOrder() &#123; return BindingBuilder.bind(getOrderQueue()).to(getOrderExchange()).with(ORDER_ROUTING_KEY).noargs(); &#125;&#125; 库存初始化至redis 在开发中可能会有这样的情景。需要在容器启动的时候执行一些内容。比如读取配置文件，数据库连接之类的。SpringBoot给我们提供了两个接口来帮助我们实现这种需求。这两个接口分别为CommandLineRunner和ApplicationRunner。他们的执行时机为容器启动完成的时候。这里选用ApplicationRunner。 1234567891011121314151617181920212223242526272829303132333435package com.sonake.seconds.kill.demo.runner;import com.sonake.seconds.kill.demo.domain.Goods;import com.sonake.seconds.kill.demo.service.GoodsService;import com.sonake.seconds.kill.demo.service.RedisService;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.ApplicationArguments;import org.springframework.boot.ApplicationRunner;import org.springframework.stereotype.Component;import java.util.List;/** * @author ：xzyuan * @date ：Created in 2019/12/26 11:39 * @description：项目启动数据初始化 * @version: 1.0 */@Component@Slf4jpublic class ApplicationStartupRunner implements ApplicationRunner &#123; @Autowired private GoodsService goodsService; @Autowired private RedisService redisService; @Override public void run(ApplicationArguments args) throws Exception &#123; List&lt;Goods&gt; list = goodsService.list(); list.forEach(goods -&gt; &#123; redisService.put(goods.getGoodsName(),goods.getStore(),20); &#125;); log.info(\"商品库存初始化至redis完毕\"); &#125;&#125; 效果如图： redis持久化.png 秒杀请求发起 在这里主要写了两个请求，主要作用见注释.在使用redis+rebbitmq实现秒杀这个接口里，并没有针对数据库的操作，是针对redis做了数据增减，然后将下单结果告知rabbitmq并实现了暂存 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package com.sonake.seconds.kill.demo.controller;import com.sonake.seconds.kill.demo.config.RabbitMQConfig;import com.sonake.seconds.kill.demo.domain.Orders;import com.sonake.seconds.kill.demo.service.GoodsService;import com.sonake.seconds.kill.demo.service.OrderService;import com.sonake.seconds.kill.demo.service.RedisService;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.ResponseBody;/** * @author ：xzyuan * @date ：Created in 2019/12/26 14:22 * @description： * @version: */@Controller@Slf4jpublic class SecController &#123; @Autowired private RabbitTemplate rabbitTemplate; @Autowired private RedisService redisService; @Autowired private OrderService orderService; @Autowired private GoodsService goodsService; /** * 使用redis+消息队列进行秒杀实现 * * @param username * @param goodsName * @return */ @RequestMapping(\"/sec\") @ResponseBody public String sec(@RequestParam(value = \"username\") String username, @RequestParam(value = \"goodsName\") String goodsName) &#123; log.info(\"参加秒杀的用户是：&#123;&#125;，秒杀的商品是：&#123;&#125;\", username, goodsName); String message = null; //调用redis给相应商品库存量减一 Long decrByResult = redisService.decrBy(goodsName); if (decrByResult &gt;= 0) &#123; /** * 说明该商品的库存量有剩余，可以进行下订单操作 */ log.info(\"用户：&#123;&#125;秒杀该商品：剩余&#123;&#125;库存，可以进行下订单操作\", username, decrByResult, goodsName); //发消息给库存消息队列，将库存数据减一 rabbitTemplate.convertAndSend(RabbitMQConfig.STORY_EXCHANGE, RabbitMQConfig.STORY_ROUTING_KEY, goodsName); //发消息给订单消息队列，创建订单 Orders orders = new Orders(); orders.setOrderName(goodsName); orders.setOrderUser(username); rabbitTemplate.convertAndSend(RabbitMQConfig.ORDER_EXCHANGE, RabbitMQConfig.ORDER_ROUTING_KEY, orders); message = \"用户\" + username + \"秒杀\" + goodsName + \"成功\"; &#125; else &#123; /** * 说明该商品的库存量没有剩余，直接返回秒杀失败的消息给用户 */ log.info(\"用户：&#123;&#125;秒杀时商品的库存量没有剩余,秒杀结束\", username); message = username + \"商品的库存量没有剩余,秒杀结束\"; &#125; return message; &#125; /** * 实现纯数据库操作实现秒杀操作 * * @param username * @param goodsName * @return */ @RequestMapping(\"/secDataBase\") @ResponseBody public String secDataBase(@RequestParam(value = \"username\") String username, @RequestParam(value = \"goodsName\") String goodsName) &#123; log.info(\"参加秒杀的用户是：&#123;&#125;，秒杀的商品是：&#123;&#125;\", username, goodsName); return goodsService.secData(username,goodsName); &#125;&#125; 消息队列的监听并消费123456789101112131415161718192021222324252627282930313233343536package com.sonake.seconds.kill.demo.service;import com.sonake.seconds.kill.demo.config.RabbitMQConfig;import com.sonake.seconds.kill.demo.domain.Orders;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;/** * @author ：xzyuan * @date ：Created in 2019/12/26 14:49 * @description：订单监听 * @version: */@Service@Slf4jpublic class MQOrderService &#123; @Autowired private OrderService orderService; /** * 监听订单消息队列，并消费 * * @param orders */ @RabbitListener(queues = RabbitMQConfig.ORDER_QUEUE) public void createOrder(Orders orders) &#123; log.info(\"收到订单消息，订单用户为：&#123;&#125;，商品名称为：&#123;&#125;\", orders.getOrderUser(), orders.getOrderName()); /** * 调用数据库orderService创建订单信息 */ //int s =Integer.valueOf(\"ssss\"); orderService.save(orders); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536package com.sonake.seconds.kill.demo.service;import com.sonake.seconds.kill.demo.config.RabbitMQConfig;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;/** * @author ：xzyuan * @date ：Created in 2019/12/26 14:47 * @description： * @version: */@Slf4j@Servicepublic class MQStoreService &#123; @Autowired private GoodsService goodsService; /** * 监听库存消息队列，并消费 * * @param goodsName */ @RabbitListener(queues = RabbitMQConfig.STORY_QUEUE) public void decrByStock(String goodsName) &#123; log.info(\"库存消息队列收到的消息商品信息是：&#123;&#125;\", goodsName); /** * 调用数据库service给数据库对应商品库存减一 */ //int s =Integer.valueOf(\"ssss\"); goodsService.decrByStore(goodsName); &#125;&#125; 测试利用压测工具jmeter模拟秒杀.点我下载,注意与jdk的版本对应关系 模拟300个用户秒杀 jmeter截图1.png jmeter截图2.png 点击请求，发起秒杀用户收到的秒杀结果 jmeter3.png jmeter4.png jmeter5.png 可以看到：有的用户秒杀成功，有的失败，因为初始化的商品库存共计200件，这里模拟300用户下单，故有100用户秒杀失败消息队列接收到的数据 rabbitmq1.png 客户端监听消息队列并进行消费 rabbitmq2.png 纯数据库秒杀 数据库秒杀1.png 可以发现，由于并发的操作，导致多个请求进来的时候读取的商品库存量都是一样的 数据库结果 数据库秒杀2.png 我设置了20用户秒杀，下单都成功了，但是数据库库存只少了6个.可以看出，由于并发的情况，导致订单超卖，所有用户都已经下单成功了，并且数据库中的库存也并未归零（随着并发量的增多，数据库中的库存会为0 ，但是会有更多的用户下单成功，也会有用户下单失败，秒杀结束 至此，这里使用了redis+rabbitmq实现了高并发秒杀场景，并有效的防止了超卖现象，同时听过使用纯数据库操作产生了超卖的现象。 另外，由于考虑实际场景，rabbitmq万一挂掉我们的消息也就丢失了，为了防止此类情况，可设置消息队列的持久化或者集群，有效避免此类情况，这里没有做展示，感兴趣的可自行百度。配置文件中rabbitmq有关重试的设置,在设置了重试次数以后，若还是没有尝试成功，消息就会被丢弃，客户端也无法获取消息，默认是一直尝试的，此处可设置手动ack的确认，处理异常，并进行相关的的消息补偿等，详情百度。","tags":[{"name":"redis","slug":"redis","permalink":"sonake.github.io/tags/redis/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"sonake.github.io/tags/rabbitmq/"},{"name":"秒杀","slug":"秒杀","permalink":"sonake.github.io/tags/%E7%A7%92%E6%9D%80/"}]},{"title":"netty学习笔记(一)","date":"2019-12-17T22:23:33.000Z","path":"2019/12/17/netty学习笔记1/","text":"初始nettyNetty是一个提供了易于使用的API的客户端/服务端框架并发高-NIO(非阻塞IO)传输快-零拷贝 Netty提供了三种线程模型(Reactor线程模型),简单说一下各自的实现1. 单线程模型所有的IO操作都由一个NIO线程处理,局限于一些小场景，高负载多并发不适用 netty单线程模型.png 1234567891011121314151617181920package com.sonake.demo;import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;/** * @author ：xzyuan * @date ：Created in 2019/12/18 10:51 * @description：netty单线程模型 * @version: 1.0 */public class Demo &#123; public static void main(String[] args) &#123; EventLoopGroup group = new NioEventLoopGroup(); ServerBootstrap bootstrap = new ServerBootstrap() .group(group) .childHandler(new HelloServerInitializer()); &#125;&#125; 2. 多线程模型由一个线程监听服务端，接收客户端的连接请求由一组NIO线程处理IO操作 123456789101112131415161718192021package com.sonake.demo;import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;/** * @author ：xzyuan * @date ：Created in 2019/12/18 10:57 * @description：netty多线程模型 * @version: 1.0 */public class Demo &#123; public static void main(String[] args) &#123; EventLoopGroup boss = new NioEventLoopGroup(1); EventLoopGroup work = new NioEventLoopGroup(); ServerBootstrap bootstrap = new ServerBootstrap() .group(boss,work) .childHandler(new HelloServerInitializer()); &#125;&#125; netty多线程模型.png 多线程模型在绝大多数场景已经可以满足业务需要，但是在一些特殊场景性能还是有局限，例如百万千万级别的并发，多线程模型处理起来就有点无力 3. 主从线程模型一组线程池接收客户端请求，一组线程池处理IO操作 netty主从线程模型.png 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.sonake.demo;import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.nio.NioServerSocketChannel;/** * @author ：xzyuan * @date ：Created in 2019/11/28 17:51 * @description：hello服务端，客户端发送一个请求，服务端会返回hello netty * @version: 1.0 */public class Demo &#123; public static void main(String[] args) throws InterruptedException &#123; //定义一对线程组 //主线程组，用于接收客户端的链接，不做任何其他处理 EventLoopGroup bossGroup = new NioEventLoopGroup(); //从线程组，主线程组会把任务丢给从线程组，让从线程组执行任务 EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; //netty服务器创建，serverBootstrap启动类 ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap .group(bossGroup,workerGroup) //设置主从线程组 .channel(NioServerSocketChannel.class) //设置通道 .childHandler(new HelloServerInitializer()); //子处理器，用于处理workerGroup //启动server，并设置端口为8088，同步启动 ChannelFuture channelFuture = serverBootstrap.bind(8088).sync(); //监听需要关闭的channel，设置为同步 channelFuture.channel().closeFuture().sync(); &#125;finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125;","tags":[{"name":"IO","slug":"IO","permalink":"sonake.github.io/tags/IO/"},{"name":"netty","slug":"netty","permalink":"sonake.github.io/tags/netty/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"sonake.github.io/tags/SpringBoot/"}]},{"title":"Sentinel+Nacos实现规则持久化","date":"2019-12-16T11:36:22.000Z","path":"2019/12/16/Sentinel-Nacos实现规则持久化/","text":"和大家聊一聊alibaba开源很好用的流控组件Sentinel Sentinel是面向分布式服务框架的轻量级流量控制框架,主要以流量为切入点,从流量控制,熔断降级,系统负载保护等多个维度来维护系统的稳定性。 123. 2012年，Sentinel诞生于阿里巴巴，其主要目标是流量控制。. 2013-2017年，Sentinel增长迅速，并成为阿里巴巴所有微服务的基本组成部分。它已在6000多个应用程序中使用，几乎涵盖了所有核心电子商务场景。. 2018年，Sentinel演变为一个开源项目。 Sentinel对于资源的控制主要通过流量(QPS)和并发线程数做控制。更多的了解可点击Sentinel使用指南 如何实现下面说说具体怎么利用Nacos实现规则的持久化 先声明一下各个组件的版本 组件 版本信息 SpringBoot 2.2.0 SpringCloud Hoxton.RELEASE Nacos 1.1.4 JDK 1.8.0_232 提一句,这里声明jdk的版本原因是:如果版本偏低,在集成sentinel的nacos配置时，读取不到参数的问题,大致版本高于1.8.0_5这个应该就可以，具体没有测试具体哪一个版本出现了偏差 第一步:Sentinel客户端配置 添加依赖12345678910&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;version&gt;1.7.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt;&lt;/dependency&gt; 添加配置新建一个SpringBoot项目，配置文件添加如下配置12345678910111213141516171819202122server: port: 8868spring: application: name: sentinel-demo cloud: sentinel: transport: #Sentinel控制台的地址 dashboard: 127.0.0.1:8192 #Sentinel的默认端口 port: 8719 #开启懒加载 eager: true datasource: ns: nacos: serverAddr: 127.0.0.1:9010 dataId: $&#123;spring.application.name&#125;-flow-rules groupId: SENTINEL_GROUP rule_type: flow dataType: json 启动下载好的nacos服务找到/nacos/conf下面的nacos-mysql.sql文件,在mysql导入运行，建立nacos对应的库表结构再该目录下打开application.properties文件，修改如下 nacos数据库信息.png 修改nacos端口.png ! 主要是修改了nacos服务的启动端口已经配置nacos的数据库信息 然后在/nacos/bin下面，因为是windows系统，单机startup.cmd启动服务即可,登录名和密码均为nacos nacos界面截图.png 第二步:Sentinel控制台改造因为Sentinel的源码提供的流控规则生效是在内存中发生的，所以当我们重启应用时，配置好的规则就会丢失，而在生产环境中，需要进行规则配置持久化，但Sentinel-dashboard源码是不具备持久化的功能，我们需要将其进行改造,采用Push架构模式更多介绍点击 下载Sentinel-dashboard源码点击下载选择sentinel-dashboard作为我们改造的源代码 改造源代码① 在src\\main\\java\\com\\alibaba\\csp\\sentinel\\dashboard\\controller\\v2下面找到FlowControllerV2.java修改前修改后 ② 在src\\test\\java\\com\\alibaba\\csp\\sentinel\\dashboard\\rule\\目录下，将nacos复制到src\\main\\java\\com\\alibaba\\csp\\sentinel\\dashboard\\rule下如图: ③ 找到配置文件application.properties文件增加nacos的配置地址： 1234#配置nacos服务的地址 nacos.url=127.0.0.1:9010 #在这里我修改了服务的端口为8192，对应第一步中配置文件的dashboard参数server.port=8192 在src\\main\\java\\com\\alibaba\\csp\\sentinel\\dashboard\\rule\\nacos\\NacosConfig.java中修改如图 修改前： 修改后： ④ 找到src\\main\\webapp\\resources\\app\\scripts\\directives\\sidebar\\下的sidebar.html该文件，修改如图 修改前： 修改后： 我将原来的缓存规则配置做了保留，新加了持久化配置的菜单 ⑤ 找打src\\main\\webapp\\resources\\app\\scripts\\controllers\\下的identity.js该文件，修改如图 然后可以直接在本地运行这个SpringBoot项目，或者进行打包后后运行，顺带启动客户端服务，Sentinel控制台用户名和密码均 为sentinel，启动后界面如下： 第三步：测试效果 客户端启动后，Sentinel控制台就会出现该该客户端的资源 先在客户端编写一个接口返回信息用于测试限流，然后重启客户端 12345678910111213141516171819package com.example.sentineldemo.controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;/** * @author ：xzyuan * @date ：Created in 2019/12/13 10:45 * @description： * @version: */@RestControllerpublic class TestController &#123; @GetMapping(\"sen\") public String sen() &#123; return \"sentinel\"; &#125;&#125; 随便点击几下，控制台就可监控到服务端的流量情况 界面2.png 我们先通过缓存配置规则来限制流量如图： 缓存规则1.png 缓存规则2.png 由于我们是手动点击，受手速及网络影响，请求的频率有限，所以选择阈值为1，使用postman进行测试效果如下： 缓存规则3.png 当我们频繁点击请求接口，超过阈值时，就会被告知访问频率过高的提示。限流成功。重启服务或者控制台。再次点击请求，限流失效，控制台缓存流控规则也没有信息，符合我们上面所说。只是发生在内存中的规则。 通过持久化配置规则来限制流量如图： 持久化规则1.png 持久化规则2.png 通过NACOS的流控规则和簇点链路都是可以进行流控规则的新增，点击新增，完成对流控规则的持久化配置查看nacos的配置列表和数据库信息: 持久化规则3.png 持久化规则4.png 持久化规则5.png 使用postman频繁点击请求接口： 缓存规则3.png 使用了nacos配置持久化，控制台是否开启对我们来说无所谓，需要补充规则配置时开启，进行规则的补充就可以，也可以直接在nacos上面新增配置文件，格数据式参照我们在控制台新增的配置即可关闭客户端，nacos，控制台程序，在此启动客户端和nacos效果如下： 缓存规则3.png 证明我们流控规则的持久化起作用了！ Sentinel-dashboard我进行了源码改造适用于nacos的持久化规则配置，改造后的代码地址,SpringCloud集成该配置也是差不多的。流控规则的持久化还有并发线程的限制，这里没有做过多演示。此外，Sentinel还提供了降级、授权，集群等很多功能，这里只对流量控制做了改造的示例，在生产环境使用Sentinel有三种模式，这里对Push模式做了改造，Sentinel还提供了apollo、Zookeeper等的第三方支持，大家可以自己研究下，大致都是类似的，详细文档","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"sonake.github.io/tags/SpringCloud/"},{"name":"java","slug":"java","permalink":"sonake.github.io/tags/java/"},{"name":"Gateway","slug":"Gateway","permalink":"sonake.github.io/tags/Gateway/"},{"name":"alibaba","slug":"alibaba","permalink":"sonake.github.io/tags/alibaba/"},{"name":"sentinel","slug":"sentinel","permalink":"sonake.github.io/tags/sentinel/"},{"name":"nacos","slug":"nacos","permalink":"sonake.github.io/tags/nacos/"}]},{"title":"数据结构中的树","date":"2019-11-26T14:20:50.000Z","path":"2019/11/26/数据结构中的树/","text":"树定义树Tree是n(n&gt;=0)个结点的有限集。n=0时称为空树。在任意一颗非空树中：1）有且仅有一个特定的称为根（Root）的结点；2）当n&gt;1时，其余结点可分为m(m&gt;0)个互不相交的有限集T1、T2、……、Tn，其中每一个集合本身又是一棵树，并且称为根的子树。 此外，树的定义还需要强调以下两点：1）n&gt;0时根结点是唯一的，不可能存在多个根结点，数据结构中的树只能有一个根结点。2）m&gt;0时，子树的个数没有限制，但它们一定是互不相交的。 如图1,普通的树结构： 图1 节点的度节点拥有的子树数目称为节点的度。例如图2所示： 图2 节点关系结点子树的根结点为该结点的孩子结点。相应该结点称为孩子结点的双亲结点。图中，A为B的双亲结点，B为A的孩子结点。同一个双亲结点的孩子结点之间互称兄弟结点。图中，结点B与结点C互为兄弟结点。 结点层次从根开始定义起，根为第一层，根的孩子为第二层，以此类推。如图3所示： 图3 树的深度树中结点的最大层次数称为树的深度或高度，图中树的深度为4。 二叉树定义二叉树是n(n&gt;=0)个结点的有限集合，该集合或者为空集（称为空二叉树），或者由一个根结点和两棵互不相交的、分别称为根结点的左子树和右子树组成。如图4所示: 图4 二叉树特点由二叉树定义以及图示分析得出二叉树有以下特点：1）每个结点最多有两个子树，所以二叉树中不存在度大于2的结点。2）左子树和右子树是有顺序的，次序不能颠倒。 二叉树性质1）在二叉树的第i层上最多有2i-1 个节点 。（i&gt;=1）2）二叉树中如果深度为k,那么最多有2k-1个节点。(k&gt;=1）3）n0=n2+1 n0表示度数为0的节点数，n2表示度数为2的节点数。4）在完全二叉树中，具有n个节点的完全二叉树的深度为[log2n]+1，其中[log2n]是向下取整。5）若对含 n 个结点的完全二叉树从上到下且从左至右进行 1 至 n 的编号，则对完全二叉树中任意一个编号为 i 的结点有如下特性： (1) 若 i=1，则该结点是二叉树的根，无双亲, 否则，编号为 [i/2] 的结点为其双亲结点; (2) 若 2i&gt;n，则该结点无左孩子， 否则，编号为 2i 的结点为其左孩子结点； (3) 若 2i+1&gt;n，则该结点无右孩子结点， 否则，编号为2i+1 的结点为其右孩子结点。斜树斜树：所有的结点都只有左子树的二叉树叫左斜树。所有结点都是只有右子树的二叉树叫右斜树。这两者统称为斜树。如图5左斜树、图6右斜树 图5左斜树 图6右斜树 满二叉树满二叉树：在一棵二叉树中。如果所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树。 图7满二叉树 满二叉树的特点有: 1) 叶子只能出现在最后一层。 2) 非叶子结点的度一定是2。 3) 在同样深度的二叉树中，满二叉树的结点个数最多，叶子数最多。 完全二叉树对一颗具有n个结点的二叉树按层编号，如果编号为i(1&lt;=i&lt;=n)的结点与同样深度的满二叉树中编号为i的结点在二叉树中位置完全相同，则这棵二叉树称为完全二叉树。 图8完全二叉树 完全二叉树的特点： 1) 叶子结点只能出现在最下层和倒数第二层。2) 最后一层的叶子结点集中在树的左部且连续。3) 倒数第二层若存在叶子结点，一定在右树且连续。4) 如果结点度为1，则该结点只有左孩子，即没有右子树。5) 同样结点数目的二叉树，完全二叉树深度最小。注：满二叉树一定是完全二叉树，但反过来不一定成立。 二叉树遍历 图9 我们针对图9进行相关的遍历 层次遍历 从根结点开始访问； 逐层进行访问，在同一层中，按从左到右的方式进行访问。 遍历的结果为:A-B-C-D-E-F-G-H-J-I 先序遍历 访问根结点; 先序遍历左子树; 先序遍历右子树。 Tips: 先访问根节点，先左子树后右子树，先父层后子层，先左节点后右节点 遍历的结果为：A-B-D-G-H-I-C-E-F-J 中序遍历 中序遍历左子树; 访问根结点; 中序遍历右子树。 Tips: 先访问左子树，再访问根节点，再访问右子树 遍历结果为： 后序遍历 后序遍历左子树; 中序遍历右子树; 访问根结点。 Tips: 先访问左子树，再访问右子树,再访问根节点， 遍历结果为：","tags":[{"name":"java","slug":"java","permalink":"sonake.github.io/tags/java/"},{"name":"数据结构","slug":"数据结构","permalink":"sonake.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"树","slug":"树","permalink":"sonake.github.io/tags/%E6%A0%91/"}]},{"title":"微服务配置中心动态刷新(SpringConfig)","date":"2019-11-26T10:30:33.000Z","path":"2019/11/26/微服务配置中心动态刷新-SpringConfig/","text":"","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"sonake.github.io/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"sonake.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"java","slug":"java","permalink":"sonake.github.io/tags/java/"},{"name":"SpringConfig","slug":"SpringConfig","permalink":"sonake.github.io/tags/SpringConfig/"}]},{"title":"数据结构与算法(二)","date":"2019-11-21T15:17:27.000Z","path":"2019/11/21/数据结构与算法-二/","text":"这里主要说一下常见的一些排序算法 先来最简单的冒泡排序 直接上代码，时间复杂度O(n^2) 1234567891011121314151617public class BubbleSort&#123; public static int[] bubbleSort(int[] arr)&#123; if(arr==null||arr.length&lt;2)&#123; return ; &#125; for(int i=0;i&lt;arr.length-1;i++)&#123; for(int j =0;j&lt;arr.length-i-1;j++)&#123; if(arr[j]&gt;arr[j+1])&#123; int temp = arr[j]; arr[j] = arr[j+1]; arr[j+1] = temp; &#125; &#125; &#125; return arr; &#125;&#125; 选择排序123456789101112131415161718public class SelectSort&#123; public static int[] selectSort(int[] arr)&#123; for(int i=0;i&lt;arr.length-1;i++)&#123; //每轮比较的元素下标 int index = i; int j; //找出最小元素的下标 for(j=i+1;j&lt;arr.length;j++)&#123; if(arr[index]&lt;arr[j])&#123; index = j; &#125; &#125; int temp = arr[index]; arr[index] = arr[i]; arr[i] = temp; &#125; &#125;&#125; 插入排序public class InsertSort{ public static int[] insertSort(int[] arr){ return null; } }","tags":[{"name":"java","slug":"java","permalink":"sonake.github.io/tags/java/"},{"name":"数据结构","slug":"数据结构","permalink":"sonake.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"sonake.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"排序","permalink":"sonake.github.io/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"数据结构与算法(一)","date":"2019-11-21T10:21:08.000Z","path":"2019/11/21/数据结构与算法-一/","text":"数组的定义或者常见的操作比较简单，就不在描述了,说说下面这个大”O”表示法 无序数组的插入耗时:常数 无序数组的插入是目前为止可以接触到的算法中唯一一个耗时与数组的大小无关的 定义这个耗时为常量K 即T = K; 实际使用中，这个数值可能受到软硬件的因素比较多，例如计算器的计算能力、运行速度、编译器的程序编译速度等等，可能需要多次 测量我们才可以得到当前环境下的这个常量数值。 线性查找：与数据项个数K成正比 线性查找中, 寻找特定项所需的比较次数平均为数据项总数的一半。设N为数据项总数，搜索时间应该是跟数据项的一半成正比， 即有下面的公式: T = K*N/2 将1/2并入K值，得到： T=KN 即线性查找的时间与数据项个数成正比。 二分查找： 与log(N)成正比 T = Klog2(N) 常量简化： T = KlogN 不要常数 大”O”表示法忽略常数，只关注数据项个数这个变量 用大”O”表示法展示运行时间 算法 大O表示法运行时间 线性查找 O(N) 二分查找 O(logn) 无序数组的插入 O(1) 有序数组的插入 O(N) 无序数组的删除 O(N) 有序数组的删除 O(N)","tags":[{"name":"java","slug":"java","permalink":"sonake.github.io/tags/java/"},{"name":"数据结构","slug":"数据结构","permalink":"sonake.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"Redis分布式锁","date":"2019-11-13T14:17:03.000Z","path":"2019/11/13/Redis分布式锁/","text":"分布式锁一般常见的有三种实现方式: 基于数据库的乐观锁; 基于Redis的分布式锁; 基于ZooKeeper的分布式锁;这篇文章着重说一下基于redis的这种实现方式 为了保证分布式锁的可用性,需要至少保证锁的实现同时满足以下四个条件–互斥性:在任何时刻,只能有一个客户端拥有锁–不能发生死锁:即有一个客户端在持有锁的期间崩溃而没有主动解锁,也能保证后续其他客户端能加锁–具有容错性:只要大部分的Redis节点正常运行,客户端就可以加锁和解锁–正确性:解铃还须系铃人,加锁和解锁必须是同一个客户端,客户端自己不能把别人加的锁给解了,加锁解锁对应同一个客户端 java代码实现引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; 实现加锁12345678910111213141516171819202122public class RedisTool &#123; private static final String LOCK_SUCCESS = \"OK\"; private static final String SET_IF_NOT_EXIST = \"NX\"; private static final String SET_WITH_EXPIRE_TIME = \"PX\"; /** * 尝试获取分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @param expireTime 超期时间 * @return 是否获取成功 */ public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125;&#125; 可以看到，我们加锁就一行代码： jedis.set(String key, String value, String nxxx, String expx, int time) 这个set()方法一共有五个形参： 第一个为key，我们使用key来当锁，因为key是唯一的。 第二个为value，我们传的是requestId，很多童鞋可能不明白，有key作为锁不就够了吗，为什么还要用到value？ 原因就是我们在上面讲到可靠性时，分布式锁要满足第四个条件解铃还须系铃人，通过给value赋值为requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。 requestId可以使用UUID.randomUUID().toString()方法生成。 第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作； 第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。 第五个为time，与第四个参数相呼应，代表key的过期时间。 总的来说，执行上面的set()方法就只会导致两种结果： 当前没有锁（key不存在），那么就进行加锁操作，并对锁设置个有效期，同时value表示加锁的客户端。已有锁存在，不做任何操作。心细的童鞋就会发现了，我们的加锁代码满足我们可靠性里描述的三个条件。 首先，set()加入了NX参数，可以保证如果已有key存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。 其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即key被删除），不会发生死锁。 最后，因为我们将value赋值为requestId，代表加锁的客户端请求标识，那么在客户端在解锁的时候就可以进行校验是否是同一个客户端。 由于我们只考虑Redis单机部署的场景，所以容错性我们暂不考虑。 错误示例1比较常见的错误示例就是使用jedis.setnx()和jedis.expire()组合实现加锁 代码如下： 123456789public class test1&#123; public static void wrongGetLock1(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; Long result = jedis.setnx(lockKey, requestId); if (result == 1) &#123; // 若在这里程序突然崩溃，则无法设置过期时间，将发生死锁 jedis.expire(lockKey, expireTime); &#125; &#125;&#125; setnx()方法作用就是SET IF NOT EXIST，expire()方法就是给锁加一个过期时间。 乍一看好像和前面的set()方法结果一样，然而由于这是两条Redis命令，不具有原子性，如果程序在执行完setnx()之后突然崩溃，导致锁没有设置过期时间。那么将会发生死锁。 网上之所以有人这样实现，是因为低版本的jedis并不支持多参数的set()方法。 错误示例2这一种错误示例就比较难以发现问题，而且实现也比较复杂。实现思路：使用jedis.setnx()命令实现加锁，其中key是锁，value是锁的过期时间。 执行过程： 1.通过setnx()方法尝试加锁，如果当前锁不存在，返回加锁成功。2.如果锁已经存在则获取锁的过期时间，和当前时间比较，如果锁已经过期，则设置新的过期时间，返回加锁成功。代码如下： 123456789101112131415161718192021222324252627public class Test2&#123; public static boolean wrongGetLock2(Jedis jedis, String lockKey, int expireTime) &#123; long expires = System.currentTimeMillis() + expireTime; String expiresStr = String.valueOf(expires); // 如果当前锁不存在，返回加锁成功 if (jedis.setnx(lockKey, expiresStr) == 1) &#123; return true; &#125; // 如果锁存在，获取锁的过期时间 String currentValueStr = jedis.get(lockKey); if (currentValueStr != null &amp;&amp; Long.parseLong(currentValueStr) &lt; System.currentTimeMillis()) &#123; // 锁已过期，获取上一个锁的过期时间，并设置现在锁的过期时间 String oldValueStr = jedis.getSet(lockKey, expiresStr); if (oldValueStr != null &amp;&amp; oldValueStr.equals(currentValueStr)) &#123; // 考虑多线程并发的情况，只有一个线程的设置值和当前值相同，它才有权利加锁 return true; &#125; &#125; // 其他情况，一律返回加锁失败 return false; &#125;&#125; 那么这段代码问题在哪里？ 由于是客户端自己生成过期时间，所以需要强制要求分布式下每个客户端的时间必须同步。 当锁过期的时候，如果多个客户端同时执行jedis.getSet()方法，那么虽然最终只有一个客户端可以加锁，但这个客户端的锁过期时间可能被其他客户端覆盖。 锁不具备拥有者标识，即任何客户端都可以解锁。 解锁代码正确姿势还是先展示代码，再带大家慢慢解释为什么这样实现： 123456789101112131415161718192021222324public class RedisTool &#123; private static final Long RELEASE_SUCCESS = 1L; /** * 释放分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @return 是否释放成功 */ public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) &#123; String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\"; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125;&#125; 可以看到，我们解锁只需要两行代码就搞定了！ 第一行代码，我们写了一个简单的Lua脚本代码。 第二行代码，我们将Lua代码传到jedis.eval()方法里，并使参数KEYS[1]赋值为lockKey，ARGV[1]赋值为requestId。eval()方法是将Lua代码交给Redis服务端执行。 那么这段Lua代码的功能是什么呢？ 其实很简单，首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）。 那么为什么要使用Lua语言来实现呢？ 因为要确保上述操作是原子性的。关于非原子性会带来什么问题，可以阅读【解锁代码-错误示例2】 那么为什么执行eval()方法可以确保原子性，源于Redis的特性，下面是官网对eval命令的部分解释： 简单来说，就是在eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令。 错误示例1最常见的解锁代码就是直接使用jedis.del()方法删除锁，这种不先判断锁的拥有者而直接解锁的方式，会导致任何客户端都可以随时进行解锁，即使这把锁不是它的。 1234567891011public class RedisTool &#123; /** * * @param jedis * @param lockKey */ public static void wrongReleaseLock1(Jedis jedis, String lockKey) &#123; jedis.del(lockKey); &#125;&#125; 错误示例2这种解锁代码乍一看也是没问题，甚至我之前也差点这样实现，与正确姿势差不多，唯一区别的是分成两条命令去执行 代码如下： 123456789101112131415161718public class RedisTool &#123; /** * * @param jedis * @param lockKey * @param requestId */ public static void wrongReleaseLock2(Jedis jedis, String lockKey, String requestId) &#123; // 判断加锁与解锁是不是同一个客户端 if (requestId.equals(jedis.get(lockKey))) &#123; // 若在此时，这把锁突然不是这个客户端的，则会误解锁 jedis.del(lockKey); &#125; &#125;&#125; 如代码注释，问题在于如果调用jedis.del()方法的时候，这把锁已经不属于当前客户端的时候会解除他人加的锁。 那么是否真的有这种场景？ 答案是肯定的，比如客户端A加锁，一段时间之后客户端A解锁，在执行jedis.del()之前，锁突然过期了，此时客户端B尝试加锁成功，然后客户端A再执行del()方法，则将客户端B的锁给解除了。 总结本文主要介绍了如何使用Java代码正确实现Redis分布式锁，对于加锁和解锁也分别给出了两个比较经典的错误示例。 其实想要通过Redis实现分布式锁并不难，只要保证能满足可靠性里的四个条件。 互联网虽然给我们带来了方便，只要有问题就可以google，然而网上的答案一定是对的吗？其实不然，所以我们更应该时刻保持着质疑精神，多想多验证。 如果你的项目中Redis是多机部署的，那么可以尝试使用Redisson实现分布式锁，这是Redis官方提供的Java组件，链接在参考阅读章节已经给出 参考阅读https://redis.io/topics/distlockhttps://redis.io/commands/evalhttps://github.com/redisson/redisson","tags":[{"name":"java","slug":"java","permalink":"sonake.github.io/tags/java/"},{"name":"redis","slug":"redis","permalink":"sonake.github.io/tags/redis/"},{"name":"分布式锁","slug":"分布式锁","permalink":"sonake.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"}]},{"title":"记录一些mysql的笔记","date":"2019-11-13T10:56:37.000Z","path":"2019/11/13/mysql笔记/","text":"mysql服务端与客户端常见的连接方式有三种：1.TCP/IP连接,这是我们目前经常采用的方式2.命名管道和共享内存 命名管道和共享内存.png 3.Unix域套接字文件 Unix域套接字文件.png mysql的启动连接有长短命令，最初是长命令，为了方便改为短命令常见长短命令的对应关系 参数名 含义 -h 表示服务器进程所在计算机的域名或者IP地址，如果服务器进程就运行在本机的话，可以省略这个参数，或者填localhost或者127.0.0.1。也可以写作 –host=主机名的形式 -u 表示用户名。也可以写作 –user=用户名的形式 -p 表示密码。也可以写作 –password=密码的形式 -P 表示端口，也可以写作–port端口 -V 表示版本信息，也可以写作–version mysql的命令参数优先级不同文件的相同参数 命令行指定参数&gt;my.cnf&gt;其他配置文件同文件的相同参数 以出现在最后的位置为准 defaults-extra-file参数可以指定额外的配置文件搜索路径 mysql索引的存储方式 mysql索引采用的存储方式为B+树","tags":[{"name":"mysql","slug":"mysql","permalink":"sonake.github.io/tags/mysql/"},{"name":"sql进阶","slug":"sql进阶","permalink":"sonake.github.io/tags/sql%E8%BF%9B%E9%98%B6/"}]},{"title":"讨论下时下很热门的容器部署,先来安装docker","date":"2019-10-20T10:56:37.000Z","path":"2019/10/20/centos7上面docker的安装/","text":"如果没有服务器的同学可以自助机安装一个虚拟机我这里是在自己的电脑上安装的虚拟机，系统版本是centos Linux release 7.6.1810(Core)为了避免一些其他错误，请切换至根用户下操作 第一步： 卸载已安装的docker：yum remove docker-*第二步： 更新系统内核：yum update第三步： 安装docker：yum install docker第四步： 启动docker：systemctl start docker第五步： 查看容器：docker ps第六步： 添加阿里云的镜像加速地址：vim /etc/docker/daemon.json 添加内容：{“registry-mirrors”: “https://aiyf7r3a.mirror.aliyuncs.com”}第七步： 重启docker：systemctl restart docker 至此docker安装完毕！","tags":[{"name":"docker","slug":"docker","permalink":"sonake.github.io/tags/docker/"},{"name":"centos","slug":"centos","permalink":"sonake.github.io/tags/centos/"}]},{"title":"Hello World","date":"2019-10-18T10:21:08.000Z","path":"2019/10/18/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]